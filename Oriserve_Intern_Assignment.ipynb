{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Task\n",
        "The task is to develop an approach that given a sample will identify the subthemes along with\n",
        "their respective sentiments.\n",
        "Submitted By Anuroop Arya"
      ],
      "metadata": {
        "id": "YJHmeOlssOdg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from transformers import pipeline\n",
        "import textwrap\n",
        "from IPython.display import Markdown\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_csv(\"/content/Evaluation-dataset.csv\", header=None)\n",
        "\n",
        "# Initialize the sentiment analysis pipeline\n",
        "mood_detector = pipeline(\"sentiment-analysis\")\n",
        "\n",
        "# Configure the GenerativeAI API\n",
        "genai.configure(api_key=\"AIzaSyDN3DjZJy8_EKhUVb0ExcDhtPQyplDw2kE\")\n",
        "\n",
        "# List available models and select one for content generation\n",
        "for brain in genai.list_models():\n",
        "    if 'generateContent' in brain.supported_generation_methods:\n",
        "        print(brain.name)\n",
        "creativity_engine = genai.GenerativeModel('gemini-pro')\n",
        "\n",
        "# Function to convert text to Markdown format\n",
        "def markdownify(text):\n",
        "    text = text.replace('â€¢', '  *')  # Adjust bullet points for Markdown\n",
        "    return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n",
        "\n",
        "# Example system prompt (we can adjust this as needed)\n",
        "garage_story_prompt = \"Tires were delivered to the garage of my choice, the garage notified me when they had been delivered. A day and time was arranged with the garage and I went and had them fitted, a hassle-free experience.\"\n",
        "\n",
        "# Function to format the response into pros and cons\n",
        "def format_pros_cons(text):\n",
        "    positives = []\n",
        "    negatives = []\n",
        "\n",
        "    # Dummy sentiment analysis for pros and cons\n",
        "    sentences = text.split('. ')\n",
        "    for sentence in sentences:\n",
        "        sentiment = mood_detector(sentence)\n",
        "        if sentiment[0]['label'] == 'POSITIVE':\n",
        "            positives.append(sentence)\n",
        "        else:\n",
        "            negatives.append(sentence)\n",
        "\n",
        "    pros_cons_text = \"### Pros:\\n\" + \"\\n\".join(f\"* {pos}\" for pos in positives)\n",
        "    pros_cons_text += \"\\n\\n### Cons:\\n\" + \"\\n\".join(f\"* {neg}\" for neg in negatives)\n",
        "    return pros_cons_text\n",
        "\n",
        "# Example of using the generative model to respond to the system prompt and the 6th line of the dataset\n",
        "retort = creativity_engine.generate_content(garage_story_prompt + df[0][5])\n",
        "\n",
        "# Format the response into pros/cons or Negatve/Positive\n",
        "pros_cons_response = format_pros_cons(retort.text)\n",
        "\n",
        "# Display the formatted response\n",
        "markdownify(pros_cons_response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "id": "ZmzKPxxirXMP",
        "outputId": "56312f50-a92c-49fc-cb73-d2ec655b55ed"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-1.0-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-1.5-flash\n",
            "models/gemini-1.5-flash-001\n",
            "models/gemini-1.5-flash-latest\n",
            "models/gemini-1.5-pro\n",
            "models/gemini-1.5-pro-001\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-pro\n",
            "models/gemini-pro-vision\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> ### Pros:\n> * **Positive:**\n> \n> * Tires delivered to the desired garage\n> * Garage notified the customer upon delivery\n> * Convenient appointment scheduling\n> * Hassle-free experience\n> * Excellent service\n> \n> **Slight Downside:**\n> \n> * Exact time of availability at the garage was not known\n> \n> ### Cons:\n"
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    }
  ]
}